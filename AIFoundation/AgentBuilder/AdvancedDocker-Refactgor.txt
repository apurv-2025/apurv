# Complete Docker and Configuration Setup

# docker-compose.yml - Development setup
version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: ai-agent-postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: ai_agents_db
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    networks:
      - ai-agent-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis for caching and sessions
  redis:
    image: redis:7-alpine
    container_name: ai-agent-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - ai-agent-network
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass redispassword
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: ai-agent-backend
    environment:
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/ai_agents_db
      - REDIS_URL=redis://:redispassword@redis:6379
      - SECRET_KEY=dev-secret-key-change-in-production
      - ENVIRONMENT=development
      - CORS_ORIGINS=http://localhost:3000,http://frontend:3000
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - uploads_data:/app/uploads
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - ai-agent-network
    restart: unless-stopped
    develop:
      watch:
        - path: ./backend
          target: /app
          action: sync

  # Frontend React App
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    container_name: ai-agent-frontend
    environment:
      - REACT_APP_API_URL=http://localhost:8000
      - REACT_APP_WS_URL=ws://localhost:8000
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    depends_on:
      - backend
    networks:
      - ai-agent-network
    restart: unless-stopped
    develop:
      watch:
        - path: ./frontend/src
          target: /app/src
          action: sync
        - path: ./frontend/public
          target: /app/public
          action: sync

  # Nginx reverse proxy (optional for development)
  nginx:
    image: nginx:alpine
    container_name: ai-agent-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - frontend
      - backend
    networks:
      - ai-agent-network
    restart: unless-stopped
    profiles:
      - with-nginx

  # Ollama for local LLM (optional)
  ollama:
    image: ollama/ollama:latest
    container_name: ai-agent-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - ai-agent-network
    restart: unless-stopped
    profiles:
      - with-ollama
    environment:
      - OLLAMA_HOST=0.0.0.0

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  uploads_data:
    driver: local
  ollama_data:
    driver: local

networks:
  ai-agent-network:
    driver: bridge

---

# docker-compose.prod.yml - Production setup
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    container_name: ai-agent-postgres-prod
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_prod_data:/var/lib/postgresql/data
    networks:
      - ai-agent-prod-network
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:7-alpine
    container_name: ai-agent-redis-prod
    volumes:
      - redis_prod_data:/data
    networks:
      - ai-agent-prod-network
    restart: always
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.prod
    container_name: ai-agent-backend-prod
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - SECRET_KEY=${SECRET_KEY}
      - ENVIRONMENT=production
      - DEBUG=false
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - ai-agent-prod-network
    restart: always

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.prod
    container_name: ai-agent-frontend-prod
    environment:
      - REACT_APP_API_URL=${BACKEND_URL}
      - REACT_APP_WS_URL=${WEBSOCKET_URL}
    depends_on:
      - backend
    networks:
      - ai-agent-prod-network
    restart: always

  nginx:
    image: nginx:alpine
    container_name: ai-agent-nginx-prod
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.prod.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - static_files:/var/www/static
    depends_on:
      - frontend
      - backend
    networks:
      - ai-agent-prod-network
    restart: always

volumes:
  postgres_prod_data:
    driver: local
  redis_prod_data:
    driver: local
  static_files:
    driver: local

networks:
  ai-agent-prod-network:
    driver: bridge

---

# backend/Dockerfile - Development
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libpq-dev \
    libmagic1 \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for better caching
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create uploads directory
RUN mkdir -p uploads logs

# Create non-root user
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]

---

# backend/Dockerfile.prod - Production
FROM python:3.11-slim as base

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libpq-dev \
    libmagic1 \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create directories
RUN mkdir -p uploads logs

# Create non-root user
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Run application with gunicorn for production
CMD ["gunicorn", "main:app", "-w", "4", "-k", "uvicorn.workers.UvicornWorker", "--bind", "0.0.0.0:8000"]

---

# frontend/Dockerfile.dev - Development
FROM node:18-alpine

WORKDIR /app

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm ci

# Copy source code
COPY . .

# Create build directory
RUN mkdir -p build

# Expose port
EXPOSE 3000

# Start development server
CMD ["npm", "start"]

---

# frontend/Dockerfile.prod - Production
FROM node:18-alpine as build

WORKDIR /app

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm ci --only=production

# Copy source code
COPY . .

# Build application
RUN npm run build

# Production stage
FROM nginx:alpine

# Copy built assets
COPY --from=build /app/build /usr/share/nginx/html

# Copy nginx configuration
COPY nginx.conf /etc/nginx/conf.d/default.conf

# Expose port
EXPOSE 80

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD curl -f http://localhost/ || exit 1

# Start nginx
CMD ["nginx", "-g", "daemon off;"]

---

# nginx/nginx.conf - Development
events {
    worker_connections 1024;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;
    
    # Logging
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';
    
    access_log /var/log/nginx/access.log main;
    error_log /var/log/nginx/error.log warn;
    
    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/javascript
        application/xml+rss
        application/json;
    
    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=auth:10m rate=5r/s;
    
    upstream backend {
        server backend:8000;
    }
    
    upstream frontend {
        server frontend:3000;
    }
    
    server {
        listen 80;
        server_name localhost;
        
        # Security headers
        add_header X-Frame-Options DENY;
        add_header X-Content-Type-Options nosniff;
        add_header X-XSS-Protection "1; mode=block";
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
        
        # Frontend
        location / {
            proxy_pass http://frontend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # WebSocket support
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
        }
        
        # API endpoints
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            
            proxy_pass http://backend/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # CORS headers for API
            add_header Access-Control-Allow-Origin $http_origin;
            add_header Access-Control-Allow-Methods "GET, POST, PUT, DELETE, OPTIONS";
            add_header Access-Control-Allow-Headers "DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization";
            add_header Access-Control-Expose-Headers "Content-Length,Content-Range";
            
            if ($request_method = 'OPTIONS') {
                add_header Access-Control-Max-Age 1728000;
                add_header Content-Type 'text/plain; charset=utf-8';
                add_header Content-Length 0;
                return 204;
            }
        }
        
        # Auth endpoints with stricter rate limiting
        location /auth/ {
            limit_req zone=auth burst=5 nodelay;
            
            proxy_pass http://backend/auth/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
        
        # WebSocket endpoint
        location /ws/ {
            proxy_pass http://backend/ws/;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
        
        # Health check
        location /health {
            proxy_pass http://backend/health;
            access_log off;
        }
        
        # Static files
        location /static/ {
            alias /var/www/static/;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }
    }
}

---

# scripts/init-db.sql - Database initialization
-- Create database if it doesn't exist
CREATE DATABASE ai_agents_db;

-- Create user for the application
CREATE USER ai_agent_user WITH ENCRYPTED PASSWORD 'ai_agent_password';

-- Grant privileges
GRANT ALL PRIVILEGES ON DATABASE ai_agents_db TO ai_agent_user;

-- Connect to the database
\c ai_agents_db;

-- Create extensions
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pgcrypto";

-- Grant schema privileges
GRANT ALL ON SCHEMA public TO ai_agent_user;
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO ai_agent_user;
GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO ai_agent_user;

---

# .env.example - Environment template
# Database Configuration
DATABASE_URL=postgresql://postgres:password@localhost:5432/ai_agents_db
POSTGRES_USER=postgres
POSTGRES_PASSWORD=password
POSTGRES_DB=ai_agents_db

# Redis Configuration
REDIS_URL=redis://:redispassword@localhost:6379
REDIS_PASSWORD=redispassword

# Security Keys (CHANGE IN PRODUCTION!)
SECRET_KEY=your-super-secret-key-change-in-production
ENCRYPTION_KEY=your-encryption-key-for-sensitive-data-32-chars
JWT_SECRET_KEY=your-jwt-secret-key-change-in-production

# LLM Configuration
LLM_PROVIDER=openai  # Options: openai, ollama, huggingface
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-3.5-turbo

# Alternative LLM Providers
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama2
HUGGINGFACE_TOKEN=your-huggingface-token

# Vector Database
VECTOR_PROVIDER=faiss  # Options: pinecone, faiss
PINECONE_API_KEY=your-pinecone-api-key
PINECONE_ENVIRONMENT=us-west1-gcp

# Application URLs
FRONTEND_URL=http://localhost:3000
BACKEND_URL=http://localhost:8000
WEBSOCKET_URL=ws://localhost:8000

# Environment
ENVIRONMENT=development  # development, staging, production
DEBUG=true

# CORS Origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# Email Configuration (Optional)
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password

# File Upload
UPLOAD_PATH=./uploads
MAX_FILE_SIZE=10485760  # 10MB in bytes
ALLOWED_FILE_TYPES=.pdf,.txt,.doc,.docx

# Rate Limiting
RATE_LIMIT_REQUESTS_PER_MINUTE=60
RATE_LIMIT_REQUESTS_PER_HOUR=1000

# HIPAA Compliance
DATA_RETENTION_DAYS=2190  # 6 years
AUDIT_LOG_RETENTION_DAYS=2555  # 7 years

# Feature Flags
ENABLE_TWO_FACTOR_AUTH=true
ENABLE_REAL_TIME_CHAT=true
ENABLE_EMR_INTEGRATIONS=true
ENABLE_ADVANCED_ANALYTICS=true

# Monitoring (Optional)
SENTRY_DSN=your-sentry-dsn
PROMETHEUS_ENABLED=false

# External Integrations (Optional)
EPIC_CLIENT_ID=your-epic-client-id
EPIC_CLIENT_SECRET=your-epic-client-secret
EPIC_FHIR_BASE_URL=https://fhir.epic.com/interconnect-fhir-oauth

ATHENAHEALTH_API_KEY=your-athena-api-key
ATHENAHEALTH_SECRET=your-athena-secret
ATHENAHEALTH_PRACTICE_ID=your-practice-id

---

# .dockerignore - Files to exclude from Docker build
**/.git
**/.gitignore
**/node_modules
**/npm-debug.log
**/.env
**/.env.local
**/.env.*.local
**/coverage
**/.nyc_output
**/*.md
**/Dockerfile*
**/docker-compose*
**/.vscode
**/.idea
**/logs
**/uploads
**/__pycache__
**/*.pyc
**/*.pyo
**/*.pyd
**/.pytest_cache
**/.coverage
**/htmlcov
**/.tox
**/venv
**/env
**/.DS_Store
**/Thumbs.db

---

# docker-compose.override.yml - Local development overrides
version: '3.8'

services:
  backend:
    environment:
      - DEBUG=true
      - LOG_LEVEL=DEBUG
    volumes:
      - ./backend:/app
      - /app/__pycache__
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload --log-level debug

  frontend:
    environment:
      - FAST_REFRESH=true
      - GENERATE_SOURCEMAP=true
    volumes:
      - ./frontend:/app
      - /app/node_modules
    command: npm start

  postgres:
    environment:
      - POSTGRES_LOG_STATEMENT=all
      - POSTGRES_LOG_MIN_DURATION_STATEMENT=0
    command: postgres -c log_statement=all -c log_destination=stderr

  redis:
    command: redis-server --loglevel debug --appendonly yes
